{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849fb886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851a35e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goes from a list stored in a df to just the value inside.\n",
    "def fix_list_format(df, col_title):\n",
    "    fixed_row = []\n",
    "    for index, row in df.iterrows():\n",
    "        str1 = row[col_title]\n",
    "        if len(str1) > 2:\n",
    "            fixed_row.append(row[col_title][1:-1])\n",
    "        else:\n",
    "            fixed_row.append(np.nan)\n",
    "    df[col_title] = fixed_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "963d787c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sc_id                  object\n",
       "supercon_formula       object\n",
       "cleaned_formula        object\n",
       "material_dict          object\n",
       "highest_Tc             object\n",
       "average_Tc            float64\n",
       "std_Tc                float64\n",
       "entry_count             int64\n",
       "matches_by_element     object\n",
       "matches_by_dict        object\n",
       "mp_ids                 object\n",
       "unit_cell_volumes      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load\n",
    "df = pd.read_excel(\"C:/Users/Droor/OneDrive - Harvard University/Desktop/Master Folder/College (2022-2026)/Hoffman summer/main_notebook/only_stable_mp_matches_jenny.xlsx\")\n",
    "df = df.drop('material_dict_queried', axis=1)\n",
    "df['material_dict'] = df['material_dict'].apply(literal_eval) #convert to list type\n",
    "fix_list_format(df, 'unit_cell_volumes')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3182b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Element</th>\n",
       "      <th>AtomicMass</th>\n",
       "      <th>AtomicNumber</th>\n",
       "      <th>FirstIonizationEnergy</th>\n",
       "      <th>AtomicRadius</th>\n",
       "      <th>BoilingPoint</th>\n",
       "      <th>BrinellHardness</th>\n",
       "      <th>CovalentRadius</th>\n",
       "      <th>Density</th>\n",
       "      <th>ElectricalConductivity</th>\n",
       "      <th>...</th>\n",
       "      <th>Resistivity</th>\n",
       "      <th>SoundSpeed</th>\n",
       "      <th>SpaceGroupNumber</th>\n",
       "      <th>SpecificHeat</th>\n",
       "      <th>ThermalConductivity</th>\n",
       "      <th>ThermalExpansion</th>\n",
       "      <th>Valence</th>\n",
       "      <th>VaporizationHeat</th>\n",
       "      <th>VolumeMagneticSusceptibility</th>\n",
       "      <th>SuperconductingPoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H</td>\n",
       "      <td>1.007940</td>\n",
       "      <td>1</td>\n",
       "      <td>1311.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-252.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>14300.0</td>\n",
       "      <td>0.1805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-2.230000e-09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He</td>\n",
       "      <td>4.002602</td>\n",
       "      <td>2</td>\n",
       "      <td>2361.3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-268.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>970.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>5193.1</td>\n",
       "      <td>0.1513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-1.050000e-09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Li</td>\n",
       "      <td>6.941000</td>\n",
       "      <td>3</td>\n",
       "      <td>519.9</td>\n",
       "      <td>167.0</td>\n",
       "      <td>1342.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>535.0000</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>9.400000e-08</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>85.0000</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>1</td>\n",
       "      <td>147.000</td>\n",
       "      <td>1.370000e-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Be</td>\n",
       "      <td>9.012182</td>\n",
       "      <td>4</td>\n",
       "      <td>898.8</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2470.00</td>\n",
       "      <td>600.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1848.0000</td>\n",
       "      <td>2.500000e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000e-08</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>190.0000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>2</td>\n",
       "      <td>297.000</td>\n",
       "      <td>-2.328000e-05</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>10.811000</td>\n",
       "      <td>5</td>\n",
       "      <td>800.2</td>\n",
       "      <td>87.0</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>2460.0000</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3</td>\n",
       "      <td>507.000</td>\n",
       "      <td>-2.140000e-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Element  AtomicMass  AtomicNumber  FirstIonizationEnergy  AtomicRadius  \\\n",
       "0       H    1.007940             1                 1311.3          53.0   \n",
       "1      He    4.002602             2                 2361.3          31.0   \n",
       "2      Li    6.941000             3                  519.9         167.0   \n",
       "3      Be    9.012182             4                  898.8         112.0   \n",
       "4       B   10.811000             5                  800.2          87.0   \n",
       "\n",
       "   BoilingPoint  BrinellHardness  CovalentRadius    Density  \\\n",
       "0       -252.87              NaN              31     0.0899   \n",
       "1       -268.93              NaN              28     0.1785   \n",
       "2       1342.00              NaN             128   535.0000   \n",
       "3       2470.00            600.0              96  1848.0000   \n",
       "4       4000.00              NaN              85  2460.0000   \n",
       "\n",
       "   ElectricalConductivity  ...   Resistivity  SoundSpeed  SpaceGroupNumber  \\\n",
       "0                     NaN  ...           NaN      1270.0             194.0   \n",
       "1                     NaN  ...           NaN       970.0             225.0   \n",
       "2            1.100000e+07  ...  9.400000e-08      6000.0             229.0   \n",
       "3            2.500000e+07  ...  4.000000e-08     13000.0             194.0   \n",
       "4            1.000000e-04  ...  1.000000e+04     16200.0             166.0   \n",
       "\n",
       "   SpecificHeat  ThermalConductivity  ThermalExpansion  Valence  \\\n",
       "0       14300.0               0.1805               NaN        1   \n",
       "1        5193.1               0.1513               NaN        0   \n",
       "2        3570.0              85.0000          0.000046        1   \n",
       "3        1820.0             190.0000          0.000011        2   \n",
       "4        1030.0              27.0000          0.000006        3   \n",
       "\n",
       "   VaporizationHeat  VolumeMagneticSusceptibility  SuperconductingPoint  \n",
       "0             0.452                 -2.230000e-09                   NaN  \n",
       "1             0.083                 -1.050000e-09                   NaN  \n",
       "2           147.000                  1.370000e-05                   NaN  \n",
       "3           297.000                 -2.328000e-05                 0.026  \n",
       "4           507.000                 -2.140000e-05                   NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load element-data\n",
    "element_data = pd.read_csv(\"C:/Users/Droor/OneDrive - Harvard University/Desktop/Master Folder/College (2022-2026)/Hoffman summer/main_notebook/element_data.csv\")\n",
    "element_data = element_data.drop(\"Unnamed: 0\", axis=1)\n",
    "numeric_columns = element_data.select_dtypes(include=np.number).columns\n",
    "element_data = element_data[[element_data.columns[0]] + list(numeric_columns)]\n",
    "element_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcccc02a",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m df_expanded \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaterial_dict\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m df_normalized \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(df_expanded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaterial_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m df_combined \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_expanded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_normalized\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m df_combined\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:360\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03malong the other axes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03mValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    347\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    348\u001b[0m     objs,\n\u001b[0;32m    349\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    358\u001b[0m )\n\u001b[1;32m--> 360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:591\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    589\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[0;32m    590\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[1;32m--> 591\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    593\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m    595\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    596\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    597\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3721\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3718\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "# Needs fixing: exploding and running the element-data-model.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Explode the column with the list of dictionaries\n",
    "df_expanded = df.explode('material_dict')\n",
    "df_normalized = pd.json_normalize(df_expanded['material_dict'])\n",
    "df_combined = pd.concat([df_expanded, df_normalized], axis=1)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d298f0c0",
   "metadata": {
    "id": "9vOm3Kl2rV49"
   },
   "source": [
    "#### **Hamidieh-style model using element data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6e059606",
   "metadata": {
    "id": "LqOJdLj8A3Gx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m element_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/content/gdrive/Shareddrives/Hoffman Lab SD/Research Projects/Machine Learning - Superconductors/11 Code/element_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m      2\u001b[0m element_data \u001b[38;5;241m=\u001b[39m element_data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;32m      3\u001b[0m numeric_columns \u001b[38;5;241m=\u001b[39m element_data\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnumber)\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n",
      "\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n",
      "\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n",
      "\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n",
      "\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n",
      "\u001b[0;32m    310\u001b[0m     )\n",
      "\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n",
      "\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n",
      "\u001b[0;32m    666\u001b[0m     dialect,\n",
      "\u001b[0;32m    667\u001b[0m     delimiter,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n",
      "\u001b[0;32m    677\u001b[0m )\n",
      "\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n",
      "\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n",
      "\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n",
      "\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n",
      "\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n",
      "\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n",
      "\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n",
      "\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n",
      "\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n",
      "\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n",
      "\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n",
      "\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n",
      "\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n",
      "\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n",
      "\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n",
      "\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n",
      "\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/Shareddrives/Hoffman Lab SD/Research Projects/Machine Learning - Superconductors/11 Code/element_data.csv'\n"
     ]
    }
   ],
   "source": [
    "element_data = pd.read_csv(\"/content/gdrive/Shareddrives/Hoffman Lab SD/Research Projects/Machine Learning - Superconductors/11 Code/element_data.csv\")\n",
    "element_data = element_data.drop(\"Unnamed: 0\", axis=1)\n",
    "numeric_columns = element_data.select_dtypes(include=np.number).columns\n",
    "element_data = element_data[[element_data.columns[0]] + list(numeric_columns)]\n",
    "element_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1467ae1",
   "metadata": {
    "id": "GjY9I7QlknA_"
   },
   "outputs": [],
   "source": [
    "df_exploded = pd.json_normalize(unique_mat_df['material_dict'])\n",
    "unique_mat_df_exploded = pd.concat([unique_mat_df.drop('material_dict', axis=1), df_exploded], axis=1)\n",
    "# unique_mat_df_exploded['n_atoms'] = unique_mat_df_exploded.iloc[:, 5:86].sum(axis=1)\n",
    "unique_mat_df_exploded.head()\n",
    "unique_mat_df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe432b",
   "metadata": {
    "id": "wBqVlCOQpPij"
   },
   "outputs": [],
   "source": [
    "unique_mat_df_exploded.to_csv(\"exploded_element\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91823960",
   "metadata": {
    "id": "gnCepKfoq27o"
   },
   "outputs": [],
   "source": [
    "max_keys = max(unique_mat_df['material_dict'], key=lambda x: len(x.keys()))\n",
    "\n",
    "# Filter the DataFrame to include only the entries with the most keys\n",
    "filtered_df = unique_mat_df[unique_mat_df['material_dict'].apply(lambda x: len(x.keys()) >= len(max_keys) - 2)]\n",
    "\n",
    "# filtered_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5fd25c",
   "metadata": {
    "id": "b643t8kxvCfq"
   },
   "outputs": [],
   "source": [
    "from numpy.ma.core import mean\n",
    "from scipy.stats import gmean\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "\n",
    "# We are going to create a 3D space with coordinates (material_name, property, feature)\n",
    "data = np.empty((1, 30, 14070), dtype=object)\n",
    "data.fill(None)\n",
    "\n",
    "# Iterate over every *material*\n",
    "for material_index, row in unique_mat_df_exploded.iterrows():\n",
    "\n",
    "  # Get the formula/name of the material early\n",
    "  material_formula = row[0]\n",
    "\n",
    "  # Get the total number of atoms in a material.\n",
    "  n_atoms = np.nansum(row[5:86])\n",
    "\n",
    "  elem_row = row[5:86]\n",
    "\n",
    "  # Create a Boolean mask for non-null entries\n",
    "  mask = elem_row.notna()\n",
    "\n",
    "  # Get the number of elements in a material:\n",
    "  # n_elements = len(elem_row[mask])\n",
    "\n",
    "  # Get intermediate variables to calculate features ---\n",
    "  atom_name_list = []\n",
    "  p_list = []\n",
    "\n",
    "  for index1, value1 in elem_row[mask].iteritems():\n",
    "    atom_name_list.append(index1)\n",
    "    p_list.append((value1)/(n_atoms))\n",
    "\n",
    "  # Iterate over every *property*\n",
    "  for property_index, property_name in enumerate(element_data.columns[1:], start=1):\n",
    "\n",
    "    t_list = []\n",
    "\n",
    "    # Go through the atoms\n",
    "    for index2, value2 in elem_row[mask].iteritems():\n",
    "\n",
    "      # Find the row where 'Element' matches the value of index2\n",
    "      element_row = element_data[element_data['Element'] == index2]\n",
    "\n",
    "      # Extract the value from the specified column (property_name)\n",
    "      property_value = element_row[property_name].values[0]\n",
    "\n",
    "      # Append the property value to t_list\n",
    "      t_list.append(property_value)\n",
    "\n",
    "    p_list = np.array(p_list)\n",
    "    t_list = np.array(t_list)\n",
    "\n",
    "    # print(atom_name_list)\n",
    "\n",
    "    # w_list = t_list / np.sum(t_list) # Could be wrong\n",
    "\n",
    "\n",
    "    # list_features = ['mean', 'weighted_mean', 'geom_mean', 'weighted_geom_mean', 'entropy', 'range', 'weighted_range', 'std', 'weighted_std']\n",
    "\n",
    "    # Add into our *3D-magic-thing* this coordinate. Problem may be that it expects indices, not names.\n",
    "    data[0][property_index][material_index] = np.mean(t_list)\n",
    "\n",
    "    # data[1][property_index][material_index] = sum(np.multiply(t_list, p_list))\n",
    "\n",
    "    # data[2][property_index][material_index] = gmean(t_list)\n",
    "\n",
    "    # data[3][property_index][material_index] = 1  # initialize it\n",
    "    # for ti, pi in zip(t_list,p_list):\n",
    "    #   data[3][property_index][material_index] *= ti ** pi\n",
    "\n",
    "    # data[4][property_index][material_index] = 0  # initialize it\n",
    "    # for wi in w_list:\n",
    "    #   data[4][property_index][material_index] -=  wi*(np.log(wi))\n",
    "\n",
    "    # # weighted_entropy\n",
    "\n",
    "    # data[5][property_index][material_index] = np.ptp(t_list)\n",
    "\n",
    "    # data[6][property_index][material_index] = np.ptp(np.multiply(t_list, p_list))\n",
    "\n",
    "    # data[7][property_index][material_index] = np.std(t_list)\n",
    "\n",
    "    # data[8][property_index][material_index] = DescrStatsW(t_list, weights=p_list, ddof=1).std\n",
    "\n",
    "\n",
    "    # Can GPT to get better when done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bcd620",
   "metadata": {
    "id": "iqxaQqHEBcB4"
   },
   "outputs": [],
   "source": [
    "from numpy import nanmean, nanstd, log, ptp\n",
    "from scipy.stats import gmean\n",
    "\n",
    "# We are going to create a 3D space with coordinates (material_name, property, feature)\n",
    "data = np.empty((9, 36, 14070), dtype=object)\n",
    "data.fill(None)\n",
    "\n",
    "# Get intermediate variables to calculate features\n",
    "elem_row = unique_mat_df_exploded.iloc[:, 5:86]\n",
    "mask = elem_row.notna()\n",
    "n_atoms = np.nansum(elem_row.values, axis=1)\n",
    "n_elements = np.sum(mask, axis=1)\n",
    "p_list = elem_row.values / n_atoms[:, np.newaxis]\n",
    "\n",
    "\n",
    "\n",
    "# # Iterate over every material\n",
    "# for material_index, row in unique_mat_df_exploded.iterrows():\n",
    "#     material_formula = row[0]\n",
    "\n",
    "#     t_list = element_data[element_data['Element'].isin(elem_row.loc[material_index][mask.loc[material_index]].index)][element_data.columns[1:]].values.flatten()\n",
    "#     w_list = t_list / np.sum(t_list)\n",
    "\n",
    "#     data[0, :, material_index] = nanmean(t_list, axis=0)\n",
    "#     data[1, :, material_index] = np.dot(t_list, p_list[material_index])\n",
    "#     data[2, :, material_index] = gmean(t_list)\n",
    "#     data[3, :, material_index] = np.prod(np.power(t_list, p_list[material_index]))\n",
    "#     data[4, :, material_index] = -np.sum(w_list * np.log(w_list))\n",
    "#     data[5, :, material_index] = ptp(t_list)\n",
    "#     data[6, :, material_index] = ptp(t_list * p_list[material_index])\n",
    "#     data[7, :, material_index] = nanstd(t_list, ddof=1)\n",
    "#     data[8, :, material_index] = DescrStatsW(t_list, weights=p_list[material_index], ddof=1).std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1bd6e",
   "metadata": {
    "id": "2XcaKIStXm23"
   },
   "outputs": [],
   "source": [
    "# Example Series with NaN values\n",
    "series = pd.Series([1, 2, np.nan, 4, 5, 6, 7, np.nan, 9, 10, np.nan, 12])\n",
    "\n",
    "# Create a Boolean mask for non-null entries\n",
    "mask = series.notna()\n",
    "\n",
    "# Iterate over the non-null entries preserving the original index\n",
    "for index, value in series[mask].iteritems():\n",
    "    print(f\"Index: {index}, Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5fe33",
   "metadata": {
    "id": "Zt3T46mUhiJE"
   },
   "outputs": [],
   "source": [
    "row = unique_mat_df_exploded.iloc[1]\n",
    "row = row[5:86]\n",
    "mask = row.notna()\n",
    "print(len(row[mask]))\n",
    "atom_name_list = []\n",
    "p_list = []\n",
    "\n",
    "for index1, value1 in elem_row[mask].iteritems():\n",
    "  atom_name_list.append(index1)\n",
    "  #p_list.append((value1)/(n_atoms))\n",
    "\n",
    "  # Iterate over every *property*\n",
    "  for property_index, property_name in enumerate(element_data.columns):\n",
    "    print(property_name)\n",
    "    print(property_index)\n",
    "    t_list = []\n",
    "\n",
    "    # Go through the atoms\n",
    "    for index2, value2 in elem_row[mask].iteritems():\n",
    "\n",
    "      # Find the row where 'Element' matches the value of index2\n",
    "      element_row = element_data[element_data['Element'] == index2]\n",
    "\n",
    "      # Extract the value from the specified column (property_name)\n",
    "      property_value = element_row[property_name].values[0]\n",
    "\n",
    "      # Append the property value to t_list\n",
    "      t_list.append(property_value)\n",
    "\n",
    "    p_list = np.array(p_list)\n",
    "    t_list = np.array(t_list)\n",
    "\n",
    "    print(t_list)\n",
    "    w_list = t_list / np.sum(t_list) # Could be wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a3e3e7",
   "metadata": {
    "id": "NWR4lTpSfANf"
   },
   "outputs": [],
   "source": [
    "t_list = np.array([1,2,3,3,4])\n",
    "p_list = np.array([53,4,83,2,3,1])\n",
    "print(t_list / np.sum(t_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa4f3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
